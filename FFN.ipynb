{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XX4lzebVPwT6"
   },
   "source": [
    "#CheXpert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4gyiizaSQHP5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.transforms import ToTensor,Resize\n",
    "\n",
    "from PIL import Image\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import csv\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as tfunc\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from PIL import Image\n",
    "import torch.nn.functional as func\n",
    "\n",
    "from sklearn.metrics.ranking import roc_auc_score\n",
    "import sklearn.metrics as metrics\n",
    "import random\n",
    "\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NoWy52zEQd_Y"
   },
   "source": [
    "Mount google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "K52zUmD2QgEe",
    "outputId": "1076d419-406a-4c63-e6a2-6237d3679afe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cf_fYW7HPztf"
   },
   "outputs": [],
   "source": [
    "baseFolder  = \"CheXpert-v1.0-small/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KyQIZO-UP1Wb"
   },
   "outputs": [],
   "source": [
    "#Utility functions for cleaning the data\n",
    "\n",
    "def cleanLabel(x):\n",
    "    \n",
    "    labelCount = 0    \n",
    "    if x.Pleural_Effusion == 1:\n",
    "        labelCount += 1\n",
    "    if x.Edema == 1:\n",
    "        labelCount += 1\n",
    "    if x.Cardiomegaly ==1:\n",
    "        labelCount += 1\n",
    "    if x.Pneumonia == 1:\n",
    "        labelCount += 1\n",
    "    return labelCount\n",
    "    \n",
    "    \n",
    "\n",
    "def getLabel(x):\n",
    "    \n",
    "    if x.Pleural_Effusion ==1:\n",
    "        return \"Pleural_Effusion\"\n",
    "    elif x.Edema == 1:\n",
    "        return \"Edema\"\n",
    "    elif x.Cardiomegaly==1:\n",
    "        return \"Cardiomegaly\"\n",
    "    elif x.Pneumonia == 1:\n",
    "        return \"Pneumonia\"\n",
    "    else:\n",
    "        return \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_GO0ks8MP-hh"
   },
   "outputs": [],
   "source": [
    "cols = ['Path',\n",
    " 'Sex',\n",
    " 'Age',\n",
    " 'View',\n",
    " 'AP/PA',\n",
    " 'No_Finding',\n",
    " 'Enlarged_Cardiomediastinum',\n",
    " 'Cardiomegaly',\n",
    " 'Lung_Opacity',\n",
    " 'Lung_Lesion',\n",
    " 'Edema',\n",
    " 'Consolidation',\n",
    " 'Pneumonia',\n",
    " 'Atelectasis',\n",
    " 'Pneumothorax',\n",
    " 'Pleural_Effusion',\n",
    " 'Pleural_Other',\n",
    " 'Fracture',\n",
    " 'Support_Devices']\n",
    "trainFile = pd.read_csv(os.path.join(baseFolder,'train.csv'), names = cols, header=0)\n",
    "validFile = pd.read_csv(os.path.join(baseFolder,'valid.csv'), names = cols, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-TQG2wyrRBB1"
   },
   "source": [
    "### Dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FUUUnXctSVRG"
   },
   "outputs": [],
   "source": [
    "labelMap = {\"Pleural_Effusion\":0, \"Edema\":1,\"Cardiomegaly\":2,\"Pneumonia\":3}\n",
    "\n",
    "def getLabelDf(x):\n",
    "    x = x[36:]          #To account for the extra \"././\" added before the Path variable\n",
    "    x = df.loc[df.Path == x] \n",
    "    return labelMap[x.label.values[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97Ms1n_rRAMv"
   },
   "outputs": [],
   "source": [
    "class LungDataset(Dataset):\n",
    "    \n",
    "\n",
    "    def __init__(self, csvFile, rootDir, transform = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            rootDir : Directory that has train, valid, train.csv and valid.csv\n",
    "            csvFile : train.csv or valid.csv\n",
    "        \"\"\"\n",
    "        \n",
    "        self.rootDir = rootDir\n",
    "        self.transform = transform\n",
    "        \n",
    "        cols = ['Path',\n",
    "                 'Sex',\n",
    "                 'Age',\n",
    "                 'View',\n",
    "                 'AP/PA',\n",
    "                 'No_Finding',\n",
    "                 'Enlarged_Cardiomediastinum',\n",
    "                 'Cardiomegaly',\n",
    "                 'Lung_Opacity',\n",
    "                 'Lung_Lesion',\n",
    "                 'Edema',\n",
    "                 'Consolidation',\n",
    "                 'Pneumonia',\n",
    "                 'Atelectasis',\n",
    "                 'Pneumothorax',\n",
    "                 'Pleural_Effusion',\n",
    "                 'Pleural_Other',\n",
    "                 'Fracture',\n",
    "                 'Support_Devices']\n",
    "        \n",
    "        self.df = pd.read_csv(os.path.join(rootDir,csvFile), names = cols, header=0)\n",
    "        \n",
    "        \n",
    "        #Modifying the path variable\n",
    "        self.df[\"Path\"] = self.df.Path.apply(lambda x : x.replace('CheXpert-v1.0-small',\"\")[1:])\n",
    "        \n",
    "        #retaining important vars\n",
    "        selectCols = ['Path',\"View\",'Sex',\"Pleural_Effusion\", \"Edema\",\"Cardiomegaly\",\"Pneumonia\"]\n",
    "        self.df = self.df[selectCols]\n",
    "        \n",
    "        self.df['isClean'] = self.df.apply(lambda x : cleanLabel(x), axis = 1)\n",
    "        #self.df[\"No\"] = (self.df.isClean == 0).astype(int)\n",
    "        #no_disease = self.df[self.df.isClean==0]\n",
    "        #Retaining only samples with 1 disease\n",
    "        self.df = self.df[self.df.isClean==1]\n",
    "        #self.df = pd.concat([self.df,no_disease])\n",
    "        \n",
    "        #Creating the label variable\n",
    "        self.df['label'] = self.df.apply(lambda x : labelMap[getLabel(x)], axis = 1)\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        imgPath = os.path.join( self.rootDir, self.df.iloc[idx].Path)\n",
    "        image = Image.open(imgPath).convert('RGB')\n",
    "        \n",
    "        label = self.df.iloc[idx].label\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NKs_qVY5RGUX"
   },
   "outputs": [],
   "source": [
    "trainDataset = LungDataset('train.csv', baseFolder, transforms.Compose([Resize((256,256)), ToTensor()]))\n",
    "validationDataset = LungDataset('valid.csv', baseFolder, transforms.Compose([Resize((256,256)), ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3raXstr9RG-1",
    "outputId": "79da6643-ef3b-4b50-e1ec-e39d56ca9fde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = next(iter(trainDataset))\n",
    "e[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HCH4axUeS3o-"
   },
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(trainDataset, batch_size= 8, shuffle = True)\n",
    "validation_loader = DataLoader(validationDataset, batch_size= 8, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6ZkmUn3URHHo",
    "outputId": "01212435-40d0-4582-a116-5da3c50be453"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 1, 0, 1, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for image, label in train_data_loader:\n",
    "    print(label)\n",
    "    \n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QjnhS5-BZMRI"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IlZg-gCLZMzk"
   },
   "source": [
    "## Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oqHb3SOhZSKW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 21 13:12:08 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.43       Driver Version: 418.43       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Quadro P2000        On   | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| N/A   47C    P3    N/A /  N/A |   3888MiB /  4042MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      3327      G   /usr/lib/xorg/Xorg                           154MiB |\r\n",
      "|    0      4506      G   /usr/bin/gnome-shell                         103MiB |\r\n",
      "|    0      6027      G   ...uest-channel-token=14680848424975100482    78MiB |\r\n",
      "|    0      7569      C   /usr/bin/python3                            3549MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwXD9_-JO70r"
   },
   "outputs": [],
   "source": [
    "LOG_DIR = './logs'\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format(LOG_DIR)\n",
    ")\n",
    "\n",
    "!if [ -f ngrok ] ; then echo \"Ngrok already installed\" ; else wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip > /dev/null 2>&1 && unzip ngrok-stable-linux-amd64.zip > /dev/null 2>&1 ; fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05j4zm8uO_Uv"
   },
   "outputs": [],
   "source": [
    "get_ipython().system_raw('./ngrok http 6006 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9ZL1lY3UPBkT",
    "outputId": "29964414-f512-4972-b042-a80f3d681aff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorboard Link: http://baf4c682.ngrok.io\n"
     ]
    }
   ],
   "source": [
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print('Tensorboard Link: ' +str(json.load(sys.stdin)['tunnels'][0]['public_url']))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H6qnFSapQU86"
   },
   "outputs": [],
   "source": [
    "# Code referenced from https://gist.github.com/gyglim/1f8dfb1b5c82627ae3efcfbbadb9f514\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc \n",
    "try:\n",
    "    from StringIO import StringIO  # Python 2.7\n",
    "except ImportError:\n",
    "    from io import BytesIO         # Python 3.x\n",
    "\n",
    "\n",
    "class Logger(object):\n",
    "    \n",
    "    def __init__(self, log_dir):\n",
    "        \"\"\"Create a summary writer logging to log_dir.\"\"\"\n",
    "        self.writer = tf.summary.FileWriter(log_dir)\n",
    "\n",
    "    def scalar_summary(self, tag, value, step):\n",
    "        \"\"\"Log a scalar variable.\"\"\"\n",
    "        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, simple_value=value)])\n",
    "        self.writer.add_summary(summary, step)\n",
    "\n",
    "    def image_summary(self, tag, images, step):\n",
    "        \"\"\"Log a list of images.\"\"\"\n",
    "\n",
    "        img_summaries = []\n",
    "        for i, img in enumerate(images):\n",
    "            # Write the image to a string\n",
    "            try:\n",
    "                s = StringIO()\n",
    "            except:\n",
    "                s = BytesIO()\n",
    "            scipy.misc.toimage(img).save(s, format=\"png\")\n",
    "\n",
    "            # Create an Image object\n",
    "            img_sum = tf.Summary.Image(encoded_image_string=s.getvalue(),\n",
    "                                       height=img.shape[0],\n",
    "                                       width=img.shape[1])\n",
    "            # Create a Summary value\n",
    "            img_summaries.append(tf.Summary.Value(tag='%s/%d' % (tag, i), image=img_sum))\n",
    "\n",
    "        # Create and write Summary\n",
    "        summary = tf.Summary(value=img_summaries)\n",
    "        self.writer.add_summary(summary, step)\n",
    "        \n",
    "    def histo_summary(self, tag, values, step, bins=1000):\n",
    "        \"\"\"Log a histogram of the tensor of values.\"\"\"\n",
    "\n",
    "        # Create a histogram using numpy\n",
    "        counts, bin_edges = np.histogram(values, bins=bins)\n",
    "\n",
    "        # Fill the fields of the histogram proto\n",
    "        hist = tf.HistogramProto()\n",
    "        hist.min = float(np.min(values))\n",
    "        hist.max = float(np.max(values))\n",
    "        hist.num = int(np.prod(values.shape))\n",
    "        hist.sum = float(np.sum(values))\n",
    "        hist.sum_squares = float(np.sum(values**2))\n",
    "\n",
    "        # Drop the start of the first bin\n",
    "        bin_edges = bin_edges[1:]\n",
    "\n",
    "        # Add bin edges and counts\n",
    "        for edge in bin_edges:\n",
    "            hist.bucket_limit.append(edge)\n",
    "        for c in counts:\n",
    "            hist.bucket.append(c)\n",
    "\n",
    "        # Create and write Summary\n",
    "        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, histo=hist)])\n",
    "        self.writer.add_summary(summary, step)\n",
    "        self.writer.flush()\n",
    "logger = Logger('./logs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24_Gy4XAPh_m"
   },
   "source": [
    "## Feedforward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Wz1SRoDTdJy"
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cJlQn1pIQPTF"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "\n",
    "input_size = 196608\n",
    "hidden_size_1 = 1024\n",
    "hidden_size_2 = 512\n",
    "hidden_size_3 = 128\n",
    "num_classes = 5\n",
    "learning_rate = 0.001\n",
    "device =  torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size_1,hidden_size_2,hidden_size_3, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size_1) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size_2, hidden_size_3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(hidden_size_3, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc4(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size_1,hidden_size_2,hidden_size_3, num_classes).to(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Giwch9Q5PhfG"
   },
   "outputs": [],
   "source": [
    "#for image, label in train_data_loader:\n",
    " #   print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zVoJRqC-TjLU"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.BCELoss(size_average = True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "epochs = 20\n",
    "# Train the model\n",
    "def train(net, optimizer, criterion, trainLoader, test_loader, epochs, size, model_name,plot):\n",
    "  model = net.to(device)\n",
    "  overall_step = 0;\n",
    "  for epoch in range(epochs):\n",
    "    loss_epoch = 0\n",
    "    for image, label in trainLoader:\n",
    "        image = image.reshape(-1, size).to(device)\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "        loss_epoch = loss\n",
    "        loss.backward()\n",
    "        print(loss)\n",
    "        optimizer.step()\n",
    "        del image\n",
    "        del label\n",
    "        \n",
    "        _, prediction = torch.max(output,1)\n",
    "        accuracy = (label == prediction.squeeze()).float().mean()\n",
    "        print(\"Accuracy: \" + str(accuracy))\n",
    "        overall_step+=1\n",
    "        if plot:\n",
    "          info = { ('loss_' + model_name): loss.item(), ('accuracy_' + model_name): accuracy.item() }\n",
    "          for tag, value in info.items():\n",
    "            logger.scalar_summary(tag, value, overall_step+1)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4097
    },
    "colab_type": "code",
    "id": "_lCMABMxVNRb",
    "outputId": "f8c9305e-62d9-4b7f-aebf-4b8aa197cf67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6098, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 768.00 MiB (GPU 0; 3.95 GiB total capacity; 3.01 GiB already allocated; 153.69 MiB free; 491.50 KiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-4b10def7a00a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m196608\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'ff'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-9c9a0614d893>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, optimizer, criterion, trainLoader, test_loader, epochs, size, model_name, plot)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dewang/.local/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     99\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 768.00 MiB (GPU 0; 3.95 GiB total capacity; 3.01 GiB already allocated; 153.69 MiB free; 491.50 KiB cached)"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, criterion, train_data_loader, validation_loader, epochs, 196608 , 'ff', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "EZCB_SI8VOYo",
    "outputId": "722102ac-ffd1-4574-bfae-0d92c0dd7fbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (fc1): Linear(in_features=196608, out_features=1024, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc4): Linear(in_features=128, out_features=5, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZKN7bCrKHQjQ"
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def to_one_hot(y, n_dims=None):\n",
    "    \"\"\" Take integer y (tensor or variable) with n dims and convert it to 1-hot representation with n+1 dims. \"\"\"\n",
    "    y_tensor = y.data if isinstance(y, Variable) else y\n",
    "    y_tensor = y_tensor.type(torch.LongTensor).view(-1, 1)\n",
    "    n_dims = n_dims if n_dims is not None else int(torch.max(y_tensor)) + 1\n",
    "    y_one_hot = torch.zeros(y_tensor.size()[0], n_dims).scatter_(1, y_tensor, 1)\n",
    "    y_one_hot = y_one_hot.view(*y.shape, -1)\n",
    "    return Variable(y_one_hot) if isinstance(y, Variable) else y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jwsg3QmRHLpY"
   },
   "outputs": [],
   "source": [
    "\n",
    "def computeAUROC (data, dataPRED, classCount):\n",
    "\n",
    "    outAUROC = []\n",
    "\n",
    "    datanpGT = data.cpu().numpy()\n",
    "    datanpPRED = dataPRED.cpu().numpy()\n",
    "\n",
    "    for i in range(classCount):\n",
    "        try:\n",
    "            outAUROC.append(roc_auc_score(datanpGT[:, i], datanpPRED[:, i]))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return outAUROC\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------- \n",
    "\n",
    "\n",
    "def test(model, dataLoaderTest, nnClassCount, class_names):   \n",
    "\n",
    "   \n",
    "    outGT = torch.FloatTensor().cuda()\n",
    "    outPRED = torch.FloatTensor().cuda()\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in dataLoaderTest:\n",
    "            image = image.reshape(-1, 196608).to(device)\n",
    "            target = to_one_hot(label.cuda(), 4).to(device)\n",
    "            outGT = torch.cat((outGT, target), 0).cuda()\n",
    "\n",
    "            out = model(image)\n",
    "            outPRED = torch.cat((outPRED, out), 0)\n",
    "        \n",
    "    aurocIndividual = computeAUROC(outGT, outPRED, nnClassCount)\n",
    "    aurocMean = np.array(aurocIndividual).mean()\n",
    "\n",
    "    print ('AUROC mean ', aurocMean)\n",
    "\n",
    "    for i in range (0, len(aurocIndividual)):\n",
    "        print (class_names[i], ' ', aurocIndividual[i])\n",
    "\n",
    "    return outGT, outPRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "G3VZcJomT6Dz",
    "outputId": "6040478c-df5c-43ef-f9e1-ebadb8880e40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC mean  0.5757443622269204\n",
      "a   0.5583333333333333\n",
      "b   0.35\n",
      "v   0.5310077519379846\n",
      "d   0.8636363636363636\n"
     ]
    }
   ],
   "source": [
    "class_names = [\"a\",\"b\",\"v\",\"d\"]\n",
    "outGT1, outPRED1 = test(model, validation_loader, 4, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "HcRPBA0PUBDs",
    "outputId": "9e63413e-2169-4127-812b-72185ccec62a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b88d9832ebbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutGT1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutPRED1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ROC for: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    fpr, tpr, threshold = metrics.roc_curve(outGT1.cpu()[:,i], outPRED1.cpu()[:,i])\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    f = plt.subplot(2, 7, i+1)\n",
    "    plt.title('ROC for: ' + class_names[i])\n",
    "    plt.plot(fpr, tpr, label = 'AUC = %0.2f' % roc_auc)\n",
    "    \n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 50\n",
    "fig_size[1] = 50\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "plt.savefig(\"ROC1345.png\", dpi=1000)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CheXpertFFN.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
